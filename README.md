# ğŸ§  Patient Risk Assessment Pipeline

## ğŸ“Œ Overview
This project runs a fully containerized **clinical note analysis pipeline** on AWS ECS Fargate.

- **Input:** Patient notes from S3 (`s3://<bucket>/Input/`)
- **Processing (ECS Fargate):**
  - Reads notes from S3
  - Retrieves the OpenAI API key from AWS Secrets Manager
  - Calls OpenAI API to assess patient risk and recommend follow-ups
  - Writes annotated CSV back to S3 (`Output/`)
  - Sends an SES email summary listing high-risk patients
- **Security:**
  - **Execution Role** â€” allows ECS to pull images, write logs, and retrieve secrets  
  - **Task Role** â€” scoped for S3 read/write, SES email sending, and optional secret fetches

---

## ğŸ— Architecture

S3 (Input CSVs) â”€â”€â–º ECS Fargate Task â”€â”€â–º S3 (Output CSVs)  
â”‚  
â”œâ”€â”€â–º OpenAI (risk scoring + recommendations)  
â””â”€â”€â–º SES (summary email)

---

## ğŸ“‚ Repo Structure

```text
src/                    # Application logic
    patient_risk_pipeline.py

fargate_deployment/     # Deployment automation
    scripts/            # Shell deployment helpers
        build_and_push.sh      # Build + push Docker image
        deploy_to_fargate.sh   # Register & run task definition
        run_all.sh             # Full one-shot deployment
        run_local.sh           # Local dry-run (no SES, throttleable)
        fetch_artifacts.sh     # Pull latest output & audit logs from S3
        seed_sample_input.sh   # Uploads a toy CSV input to S3
        setup_iam.sh           # Creates/attaches IAM roles & policies
        teardown_all.sh        # Clean up roles/resources
        validate_config.sh     # Sanity check config.env
    policies/           # IAM trust & access JSON policies
    templates/          # ECS task definition templates

config.env.example       # Sample environment configuration  
requirements.txt         # Python + pytest dependencies  
Dockerfile               # Container build file  
pytest.ini               # Pytest settings (quiet mode)  
test/                    # Lightweight local tests  
```

## ğŸš€ Quick Start

The easiest way to deploy is with the one-shot runner:

```bash
cp config.env.example config.env
# Edit config.env with your AWS_ACCOUNT_ID, region, S3 paths, SES emails, etc.

cd fargate_deployment/scripts
./run_all.sh
```

After this completes:

    âœ… Processed CSV is written to your S3 Output path

    âœ… Email notification is sent via SES

    âœ… Audit JSON summary is stored in s3://<AUDIT_BUCKET>/<AUDIT_PREFIX>/

ğŸ›  Useful Scripts

    setup_iam.sh â€” one-time IAM roles/policies

    build_and_push.sh â€” build + push Docker image

    deploy_to_fargate.sh â€” register & run the ECS task

    run_local.sh â€” run the pipeline locally with DRY_RUN_EMAIL=true and MAX_NOTES=5

    fetch_artifacts.sh â€” download latest output CSV + audit JSON locally

    seed_sample_input.sh â€” upload a toy CSV so you can demo the pipeline quickly

    teardown_all.sh â€” remove IAM roles/policies when cleaning up

ğŸ§ª Testing

This repo includes lightweight unit tests (no AWS calls):

pip install -r requirements.txt
pytest

Covers:

    Risk score extraction

    Parsing of model responses

    Schema merge logic

ğŸ”’ Security Notes

    No secrets are committed â€” OpenAI API key lives in AWS Secrets Manager.

    IAM roles follow least privilege principle.

    .gitignore ensures sensitive files (like config.env) are not committed.

    SES sandbox requires verifying both EMAIL_FROM and EMAIL_TO addresses.

ğŸ‰ Demo Workflow

# One-time IAM setup
./fargate_deployment/scripts/setup_iam.sh

# Upload toy input CSV
./fargate_deployment/scripts/seed_sample_input.sh

# Run full pipeline
./fargate_deployment/scripts/run_all.sh

# Fetch outputs locally
./fargate_deployment/scripts/fetch_artifacts.sh

Artifacts will be in /tmp/patient-pipeline-artifacts/ and your SES inbox.