# =========================
# AWS Account & Region (REQUIRED)
# =========================
AWS_ACCOUNT_ID=123456789012
AWS_REGION=us-east-1

# =========================
# ECS / Fargate (REQUIRED)
# =========================
ECS_CLUSTER_NAME=patient-pipeline-cluster
TASK_FAMILY=patient-pipeline-task

# Canonical role ARNs
# - Execution role: pulls from ECR, writes logs, injects secrets at start
# - Task role     : app runtime access to S3/SES (and Secrets only if you enable runtime fetching)
TASK_EXECUTION_ROLE=arn:aws:iam::123456789012:role/PatientPipelineECSExecutionRole
TASK_ROLE=arn:aws:iam::123456789012:role/PatientPipelineECSTaskRole

# =========================
# Networking (REQUIRED)
# =========================
# Comma-separate for multiple subnet/SG IDs
FARGATE_SUBNET_IDS=subnet-xxxxxxxx
FARGATE_SECURITY_GROUP_IDS=sg-xxxxxxxx
# ENABLED for public subnets with IGW, DISABLED for private+NAT. AUTO lets deploy script detect.
ASSIGN_PUBLIC_IP=ENABLED

# =========================
# ECR / Image (REQUIRED)
# =========================
ECR_REPO_NAME=patient-pipeline
ECR_REPO_URI=${AWS_ACCOUNT_ID}.dkr.ecr.${AWS_REGION}.amazonaws.com/${ECR_REPO_NAME}
# Optional explicit override (e.g., pin to a tag or digest)
# IMAGE_URI=${ECR_REPO_URI}:my-tag

# =========================
# S3 IO (RECOMMENDED)
# =========================
# Bucket names used for IAM scoping
S3_INPUT_BUCKET=my-input-bucket
S3_OUTPUT_BUCKET=my-output-bucket

# Full S3 paths the app will use
INPUT_S3=s3://my-input-bucket/Input/sample.csv
OUTPUT_S3=s3://my-output-bucket/Output/output_fargate.csv

# Audit logs (optional; defaults to OUTPUT bucket + audit_logs prefix)
AUDIT_BUCKET=my-output-bucket
AUDIT_PREFIX=audit_logs

# =========================
# Email (REQUIRED in SES sandbox: verify both FROM and TO)
# =========================
EMAIL_FROM=your_email@example.com
EMAIL_TO=recipient_email@example.com
EMAIL_SUBJECT="High-Risk Patient Report"

# =========================
# Pipeline Parameters
# =========================
# Physician filter (comma-separated IDs). Leave empty to include all.
PHYSICIAN_ID_LIST=1
# Risk threshold in [0,1]; rows with score >= threshold get recommendations
THRESHOLD=0.94
# Optional date window; if omitted, the app uses the last 7 days (UTC)
START_DATE=2024-05-01
END_DATE=2024-05-07

# =========================
# LLM (Model + Throttle)
# =========================
OPENAI_MODEL=gpt-4o-mini
OPENAI_THROTTLE_SEC=0

# =========================
# Logging (REQUIRED)
# =========================
LOG_GROUP=/ecs/patient-pipeline
LOG_STREAM_PREFIX=ecs
# Optional if your scripts support it:
# LOG_RETENTION_DAYS=14

# =========================
# Secrets (choose one path; prefer Secrets Manager)
# =========================
# Preferred: name or ARN of a Secrets Manager secret; deploy script injects it via Execution role.
OPENAI_API_KEY_SECRET_NAME=openai/api-key

# Fallback (dev only): inject plaintext value directly (avoid in prod)
# OPENAI_API_KEY=sk-plain-text-dev-key

# If you want the app to fetch the secret at runtime (instead of injection), set true and re-run setup_iam.sh
# APP_FETCHES_OPENAI_SECRET_AT_RUNTIME=false

# =========================
# Demo / Safety Toggles (optional)
# =========================
# Skip SES send; logs the composed email body instead
DRY_RUN_EMAIL=false
# Cap number of notes processed (0 = no cap)
MAX_NOTES=0

# =========================
# RAG (Retrieval-Augmented Generation) â€” OPTIONAL
# =========================

# Master switch (pipeline behaves exactly as before when false)
RAG_ENABLED=true

# Path to knowledge base CSV (local path OR s3://bucket/key)
# Must contain at least: title, text
RAG_KB_PATH=s3://medical-note-llm/Input/clinical_kb.csv

# Number of KB chunks to retrieve per note
RAG_TOP_K=4

# Safety cap on total characters injected into the prompt
RAG_MAX_CHARS=2500

